{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "URL = 'https://www.dol.gov/agencies/whd/state/minimum-wage/tipped'\n",
    "\n",
    "FOOTNOTE_MAP = {}\n",
    "\n",
    "def extract_footnotes_from_page():\n",
    "    global FOOTNOTE_MAP\n",
    "    try:\n",
    "        response = requests.get(URL)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        page_text = soup.get_text()\n",
    "        footnote_start = page_text.find('FOOTNOTES')\n",
    "        \n",
    "        if footnote_start != -1:\n",
    "            footnote_section = page_text[footnote_start:footnote_start + 10000]  \n",
    "            \n",
    "            lines = footnote_section.split('\\n')\n",
    "            current_footnote = None\n",
    "            current_text = []\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                    \n",
    "                match = re.match(r'^(\\d+)\\s+(.+)', line)\n",
    "                if match:\n",
    "                    if current_footnote and current_text:\n",
    "                        FOOTNOTE_MAP[current_footnote] = ' '.join(current_text).strip()\n",
    "                    \n",
    "                    current_footnote = match.group(1)\n",
    "                    current_text = [match.group(2)]\n",
    "                elif current_footnote and line and not line.startswith('Prepared By'):\n",
    "                    current_text.append(line)\n",
    "                elif line.startswith('Prepared By'):\n",
    "                    break\n",
    "            \n",
    "            if current_footnote and current_text:\n",
    "                FOOTNOTE_MAP[current_footnote] = ' '.join(current_text).strip()\n",
    "        \n",
    "        print(f\"‚úÖ Encontradas {len(FOOTNOTE_MAP)} footnotes\")\n",
    "        for num, text in list(FOOTNOTE_MAP.items())[:3]:\n",
    "            print(f\"   [{num}] {text[:60]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao extrair footnotes: {e}\")\n",
    "\n",
    "def extract_footnote_numbers(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    numbers = re.findall(r'(\\d+)', text)\n",
    "    return [num for num in numbers if num in FOOTNOTE_MAP]\n",
    "\n",
    "def clean_jurisdiction_name(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    cleaned = re.sub(r'[\\d\\*:]+$', '', text).strip()\n",
    "    return cleaned\n",
    "\n",
    "def get_law_text(text):\n",
    "    footnotes = extract_footnote_numbers(text)\n",
    "    if not footnotes:\n",
    "        return ''\n",
    "    \n",
    "    laws = []\n",
    "    for num in footnotes:\n",
    "        if num in FOOTNOTE_MAP:\n",
    "            laws.append(f\"[{num}] {FOOTNOTE_MAP[num]}\")\n",
    "    \n",
    "    return ' | '.join(laws)\n",
    "\n",
    "def is_subcategory_row(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    subcategory_indicators = [\n",
    "        'hotel', 'restaurant', 'bartender', 'business', 'employer',\n",
    "        'company', 'establishment', 'enterprise', 'annual sales',\n",
    "        'gross sales', 'covered by', 'not covered by', 'employees',\n",
    "        'full-time', 'part-time', 'opportunity', 'seasonal'\n",
    "    ]\n",
    "    \n",
    "    return any(indicator in text_lower for indicator in subcategory_indicators)\n",
    "\n",
    "def detect_regional_variations(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    patterns = [\n",
    "        r'\\$[\\d,]+\\.?\\d*\\s*\\([^)]+\\)',  \n",
    "        r'[\\d,]+\\.?\\d*\\s*\\([^)]+\\)',    \n",
    "    ]\n",
    "    \n",
    "    variations = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            # Extrair valor e regi√£o\n",
    "            value_match = re.search(r'([\\d,]+\\.?\\d*)', match)\n",
    "            region_match = re.search(r'\\(([^)]+)\\)', match)\n",
    "            \n",
    "            if value_match and region_match:\n",
    "                variations.append({\n",
    "                    'value': value_match.group(1),\n",
    "                    'region': region_match.group(1)\n",
    "                })\n",
    "    \n",
    "    return variations\n",
    "\n",
    "def scrape_all_tipped_wages():\n",
    "    response = requests.get(URL)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table')\n",
    "    if not table:\n",
    "        raise ValueError('‚ùå Tabela n√£o encontrada na p√°gina')\n",
    "    \n",
    "    headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "    headers.extend(['Law', 'Observation'])\n",
    "    \n",
    "    print(f\"üìä Headers encontrados: {headers}\")\n",
    "    \n",
    "    data = []\n",
    "    current_jurisdiction = None\n",
    "    current_law = ''\n",
    "    \n",
    "    all_rows = table.find_all('tr')[1:]  \n",
    "    \n",
    "    i = 0\n",
    "    while i < len(all_rows):\n",
    "        row = all_rows[i]\n",
    "        cols = row.find_all(['td', 'th'])\n",
    "        row_texts = [td.get_text(strip=True) for td in cols]\n",
    "        \n",
    "        if len(row_texts) >= 3 and row_texts[0]:\n",
    "            jurisdiction_raw = row_texts[0]\n",
    "            current_jurisdiction = clean_jurisdiction_name(jurisdiction_raw)\n",
    "            current_law = get_law_text(jurisdiction_raw)\n",
    "            \n",
    "            print(f\"\\nüèõÔ∏è  Processando: {current_jurisdiction}\")\n",
    "            if current_law:\n",
    "                print(f\"   üìã Lei encontrada: {current_law[:100]}...\")\n",
    "            \n",
    "            regional_variations = []\n",
    "            for col_idx, cell_text in enumerate(row_texts):\n",
    "                variations = detect_regional_variations(cell_text)\n",
    "                if variations:\n",
    "                    print(f\"   üåç Varia√ß√µes regionais encontradas em '{headers[col_idx]}': {len(variations)}\")\n",
    "                    for var in variations:\n",
    "                        regional_variations.append({\n",
    "                            'column': headers[col_idx] if col_idx < len(headers) - 2 else 'Unknown',\n",
    "                            'value': var['value'],\n",
    "                            'region': var['region']\n",
    "                        })\n",
    "            \n",
    "            if regional_variations:\n",
    "                regions = set([var['region'] for var in regional_variations])\n",
    "                for region in regions:\n",
    "                    region_dict = {}\n",
    "                    region_dict['Jurisdiction'] = current_jurisdiction\n",
    "                    region_dict['Law'] = current_law\n",
    "                    region_dict['Observation'] = region\n",
    "                    \n",
    "                    for j, header in enumerate(headers[1:-2]):\n",
    "                        if j + 1 < len(row_texts):\n",
    "                            region_dict[header] = row_texts[j + 1]\n",
    "                        else:\n",
    "                            region_dict[header] = ''\n",
    "                    \n",
    "                    for var in regional_variations:\n",
    "                        if var['region'] == region and var['column'] in region_dict:\n",
    "                            region_dict[var['column']] = f\"${var['value']}\"\n",
    "                    \n",
    "                    data.append(region_dict)\n",
    "            \n",
    "            subcategories = []\n",
    "            j = i + 1\n",
    "            while j < len(all_rows):\n",
    "                sub_row = all_rows[j]\n",
    "                sub_cols = sub_row.find_all(['td', 'th'])\n",
    "                sub_texts = [td.get_text(strip=True) for td in sub_cols]\n",
    "                \n",
    "                if len(sub_texts) >= 3 and sub_texts[0] and not is_subcategory_row(sub_texts[0]):\n",
    "                    break\n",
    "                \n",
    "                if len(sub_texts) > 0 and sub_texts[0] and is_subcategory_row(sub_texts[0]):\n",
    "                    subcategory = {\n",
    "                        'category': sub_texts[0],\n",
    "                        'data': sub_texts\n",
    "                    }\n",
    "                    subcategories.append(subcategory)\n",
    "                    print(f\"   üë• Subcategoria: {sub_texts[0]}\")\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            if subcategories:\n",
    "                for sub in subcategories:\n",
    "                    sub_dict = {}\n",
    "                    sub_dict['Jurisdiction'] = current_jurisdiction\n",
    "                    sub_dict['Law'] = current_law\n",
    "                    sub_dict['Observation'] = sub['category']\n",
    "                    \n",
    "                    for k, header in enumerate(headers[1:-2]):\n",
    "                        if k + 1 < len(sub['data']) and sub['data'][k + 1]:\n",
    "                            sub_dict[header] = sub['data'][k + 1]\n",
    "                        elif k + 1 < len(row_texts):\n",
    "                            \n",
    "                            sub_dict[header] = row_texts[k + 1]\n",
    "                        else:\n",
    "                            sub_dict[header] = ''\n",
    "                    \n",
    "                    data.append(sub_dict)\n",
    "            \n",
    "            elif not regional_variations:\n",
    "                simple_dict = {}\n",
    "                simple_dict['Jurisdiction'] = current_jurisdiction\n",
    "                simple_dict['Law'] = current_law\n",
    "                simple_dict['Observation'] = ''\n",
    "                \n",
    "                for k, header in enumerate(headers[1:-2]):\n",
    "                    if k + 1 < len(row_texts):\n",
    "                        simple_dict[header] = row_texts[k + 1]\n",
    "                    else:\n",
    "                        simple_dict[header] = ''\n",
    "                \n",
    "                data.append(simple_dict)\n",
    "            \n",
    "            i = j  \n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col not in ['Law', 'Observation']:\n",
    "            df[col] = df[col].apply(lambda x: re.sub(r'[\\d\\*]+$', '', str(x)).strip() if isinstance(x, str) else x)\n",
    "    \n",
    "    df = df.sort_values(by='Jurisdiction').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    extract_footnotes_from_page()\n",
    "    \n",
    "    df_tips = scrape_all_tipped_wages()\n",
    "\n",
    "    \n",
    "    examples = df_tips.head(10)\n",
    "    for _, row in examples.iterrows():\n",
    "        print(f\"\\nüèõÔ∏è  {row['Jurisdiction']}\")\n",
    "        if row['Law']:\n",
    "            print(f\"   üìã Lei: {row['Law'][:80]}...\")\n",
    "        if row['Observation']:\n",
    "            print(f\"   üìù Observa√ß√£o: {row['Observation']}\")\n",
    "        print(f\"   üí∞ Sal√°rio m√≠n.: {row.get('Basic Combined Cash & Tip Minimum Wage Rate', 'N/A')}\")\n",
    "    \n",
    "    filename = 'tipped_minimum_wage_complete.csv'\n",
    "    df_tips.to_csv(filename, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datarisk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
