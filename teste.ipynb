{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ed7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/projeto_adp/.pj_mwgt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import tiktoken\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.dol.gov'\n",
    "\n",
    "load_dotenv()\n",
    " \n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0bb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    \"\"\"Fetch HTML content from a given URL.\"\"\"\n",
    "    response = req.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    return response.text\n",
    "\n",
    "def search_for_link(html):\n",
    "    \"\"\"Parse HTML and extract relevant data.\"\"\"\n",
    "    data = []\n",
    "    for link in html.find_all('a', href=True):\n",
    "        data.append({\n",
    "            'text': link.get_text(strip=True),\n",
    "            'url': BASE_URL + link['href'] if link['href'].startswith('/') else link['href']\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def adjust_text(soup, link):\n",
    "    \"\"\"Substitui footnotes <a href=\"#...\"> pelo texto do rodapé sem o número.\"\"\"\n",
    "    if not link:\n",
    "        return soup.get_text(\" \", strip=True)\n",
    "\n",
    "    url = link[0]['url']\n",
    "    href_html = get_html(url)\n",
    "    href_soup = BeautifulSoup(href_html, \"html.parser\")\n",
    "\n",
    "    if '#' in url:\n",
    "        footnote_id = url.split('#')[-1]\n",
    "        div = href_soup.find('div', {'id': footnote_id})\n",
    "        if div:\n",
    "            for sup in div.find_all(\"sup\"):\n",
    "                sup.decompose()\n",
    "            footnote_text = div.get_text(strip=True)\n",
    "\n",
    "            for a in soup.find_all(\"a\", href=True):\n",
    "                if footnote_id in a[\"href\"]:\n",
    "                    a.replace_with(\" \" + footnote_text + \" \")\n",
    "\n",
    "    return soup.get_text(\" \", strip=True)\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normaliza caracteres, remove espaços extras e caracteres de controle.\"\"\"\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = \"\".join(ch for ch in text if unicodedata.category(ch)[0] != \"C\")\n",
    "    text = \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c116b44",
   "metadata": {},
   "source": [
    "__Get HTML__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f691ad2",
   "metadata": {},
   "source": [
    "## Check if Guam, Northen Mariana Island, Puerto Rico, Virgin Island, America Samoa need to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fba1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_html(f\"{BASE_URL}/agencies/whd/minimum-wage/state\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "cat = soup.find('div', {\"id\": \"states\"})\n",
    "state = cat.find_all('div')\n",
    "\n",
    "docs = {}\n",
    "\n",
    "for state_name in state:\n",
    "    if state_name.get('id').lower() == 'as': # America Samoa is a special case\n",
    "        continue\n",
    "    link = search_for_link(state_name)\n",
    "\n",
    "    # pega os irmãos após o <h2> (já como soup)\n",
    "    siblings = state_name.h2.find_next_siblings()\n",
    "    temp_soup = BeautifulSoup(\"\".join(str(s) for s in siblings), \"html.parser\")\n",
    "\n",
    "    # 1. Substitui footnotes\n",
    "    clean_text = adjust_text(temp_soup, link)\n",
    "\n",
    "    # 2. Normaliza texto\n",
    "    norm_text = normalize_text(clean_text)\n",
    "    norm_text = f\"For the state of the {state_name.h2.text} the laws of mimum wage is: \" + norm_text\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    docs[doc_id] = {\"text\": norm_text, \"metadata\": {\"state\": state_name.h2.text, 'text':norm_text}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff510355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f9dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"PINECONE_API\")\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index_name = 'firtsindex'\n",
    "indexes = pc.list_indexes()\n",
    "index_names = [index.name for index in indexes]\n",
    "if index_name not in index_names:\n",
    "    pc.create_index(name=index_name,\n",
    "                dimension=384,\n",
    "                spec=ServerlessSpec(cloud='aws',region='us-east-1'),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc72060",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index('firstindex')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dd01d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_pinecone(doc, model, index):\n",
    "    for id, state in doc.items():\n",
    "        embeddings = model.encode(state['text']).tolist()\n",
    "\n",
    "        pinecone_data = {\n",
    "            \"id\": id,\n",
    "            \"values\": embeddings,\n",
    "            \"metadata\": state[\"metadata\"]\n",
    "        }\n",
    "\n",
    "        index.upsert(vectors=[pinecone_data])\n",
    "add_to_pinecone(docs,model, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb84d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(index, query, n_results):\n",
    "    query_embedding = model.encode([query]).tolist()[0]\n",
    "    results = index.query(vector=query_embedding,\n",
    "                          top_k=n_results,\n",
    "                          include_metadata=True)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f5f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "groq_api_key = os.getenv(\"GROQ_API\")\n",
    "client_groq = Groq(api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f20437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_context(results):\n",
    "    return \"\\n\\n\".join([match['metadata']['text'] for match in results['matches']])\n",
    "\n",
    "def get_prompt(context: str, query: str):\n",
    "    prompt = f\"\"\"Based on the following context and conversation history, \n",
    "        please provide a relevant and contextual response. \n",
    "        If the answer cannot be derived from the context, only use the conversation history \n",
    "        or say \"I cannot answer this based on the provided information.\"\n",
    "\n",
    "        Context from documents:\n",
    "        {context}\n",
    "\n",
    "        Human: {query}\n",
    "\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_response(query: str, context: str):\n",
    "    \"\"\"Generate a response using Groq's Llama-3.1-8b-instant with conversation history\"\"\"\n",
    "    # Construct the prompt\n",
    "    prompt = get_prompt(context, query)\n",
    "\n",
    "    try:\n",
    "        # Create the chat completion request\n",
    "        completion = client_groq.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about the minimal wage on USA\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # Process and return the streamed response\n",
    "        response_content = []\n",
    "        for chunk in completion:\n",
    "            content = chunk.choices[0].delta.content or \"\"\n",
    "            response_content.append(content)\n",
    "\n",
    "        # Combine the response into a single string\n",
    "        response = \"\".join(response_content)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f1a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(pinecone_index, query: str, n_chunks: int = 2):\n",
    "    \"\"\"Perform RAG query: retrieve relevant chunks and generate an answer using Pinecone.\"\"\"\n",
    "    # Retrieve relevant chunks using Pinecone\n",
    "    results = semantic_search(pinecone_index, query, n_chunks)\n",
    "    context = get_context(results)\n",
    "\n",
    "    # Generate response using Groq\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c5c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta:  What is the California minimal wage? Have any extra points? Bullet points\n",
      "Reposta:  The basic minimum wage in California is $16.50 per hour. Additionally, there are the following premium pay rules for overtime hours worked:\n",
      "\n",
      "* Daily:\n",
      "  • Any work in excess of 8 hours in a workday is paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  • Any work in excess of 12 hours in a day is paid at double the regular rate of pay\n",
      "* Weekly:\n",
      "  • Any work in excess of 40 hours in a week is paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  • The first 8 hours worked on the seventh day of a workweek are paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  • Any work in excess of 8 hours on the seventh day of a workweek is paid at double the regular rate of pay\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the California minimal wage? Have any extra points? Bullet points'\n",
    "response = rag_query(index, query)\n",
    "\n",
    "print('Pergunta: ', query)\n",
    "\n",
    "print('Reposta: ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feda743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'data/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'data/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': 'data/vdb_chunks.json'} 0 data\n",
      "Rerank is enabled but no rerank_model_func provided. Reranking will be skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /embeddings in 0.393398 seconds\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Quick check to confirm\n",
    "print(\"OPENAI_API_KEY loaded:\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "\n",
    "# --- LightRAG setup ---\n",
    "from lightrag import LightRAG\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=\"data/\",\n",
    "    embedding_func=openai_embed,\n",
    "    llm_model_func=gpt_4o_mini_complete,\n",
    ")\n",
    "\n",
    "# Initialize storages\n",
    "await rag.initialize_storages()\n",
    "await initialize_pipeline_status()\n",
    "\n",
    "# # Insert your docs\n",
    "for id, state in docs.items():\n",
    "    await rag.ainsert(state['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3bf5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"### Overview of Minimum Wage Rates\\n\\nThe highest minimum wage in the United States is currently set in the **District of Columbia**, where it stands at **$17.95** per hour. This rate reflects the jurisdiction's commitment to ensuring fair compensation for workers.\\n\\n### State Comparisons\\n\\nFollowing the District of Columbia, **California** has one of the highest state minimum wages at **$16.50** per hour, joined closely by **Washington** at **$16.66** per hour. **Connecticut** also maintains a significant minimum wage at **$16.35** per hour, while **Oregon** sets its standard rate at **$15.05**, with higher rates for specific areas like the Portland Metro Area at **$16.30** per hour.\\n\\n### Additional Context\\n\\nDifferent states have varying rates influenced by local economic conditions and labor policies. As such, the minimum wage shows significant diversity across the country, emphasizing the ongoing efforts to adjust for economic changes and living costs.\\n\\n### References\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightrag import QueryParam\n",
    "result = await rag.aquery(\"What is the biggest minimal wage?\", param=QueryParam(mode=\"mix\"))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4170de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grafo_lightrag.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"grafo_lightrag.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7cab48305400>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook=True, height=\"750px\", width=\"100%\", cdn_resources='remote')\n",
    "net.show(\"grafo_lightrag.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pj_mwgt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
