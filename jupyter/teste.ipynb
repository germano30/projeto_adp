{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ed7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/projeto_adp/.pj_mwgt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import re\n",
    "import tiktoken\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.dol.gov'\n",
    "\n",
    "load_dotenv()\n",
    " \n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0bb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    \"\"\"Fetch HTML content from a given URL.\"\"\"\n",
    "    response = req.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    return response.text\n",
    "\n",
    "def search_for_link(html):\n",
    "    \"\"\"Parse HTML and extract relevant data.\"\"\"\n",
    "    data = []\n",
    "    for link in html.find_all('a', href=True):\n",
    "        data.append({\n",
    "            'text': link.get_text(strip=True),\n",
    "            'url': BASE_URL + link['href'] if link['href'].startswith('/') else link['href']\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n",
    "def adjust_text(soup, link):\n",
    "    \"\"\"Substitui footnotes <a href=\"#...\"> pelo texto do rodap√© sem o n√∫mero.\"\"\"\n",
    "    if not link:\n",
    "        return soup.get_text(\" \", strip=True)\n",
    "\n",
    "    url = link[0]['url']\n",
    "    href_html = get_html(url)\n",
    "    href_soup = BeautifulSoup(href_html, \"html.parser\")\n",
    "\n",
    "    if '#' in url:\n",
    "        footnote_id = url.split('#')[-1]\n",
    "        div = href_soup.find('div', {'id': footnote_id})\n",
    "        if div:\n",
    "            for sup in div.find_all(\"sup\"):\n",
    "                sup.decompose()\n",
    "            footnote_text = div.get_text(strip=True)\n",
    "\n",
    "            for a in soup.find_all(\"a\", href=True):\n",
    "                if footnote_id in a[\"href\"]:\n",
    "                    a.replace_with(\" \" + footnote_text + \" \")\n",
    "\n",
    "    return soup.get_text(\" \", strip=True)\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normaliza caracteres, remove espa√ßos extras e caracteres de controle.\"\"\"\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = \"\".join(ch for ch in text if unicodedata.category(ch)[0] != \"C\")\n",
    "    text = \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c116b44",
   "metadata": {},
   "source": [
    "__Get HTML__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f691ad2",
   "metadata": {},
   "source": [
    "## Check if Guam, Northen Mariana Island, Puerto Rico, Virgin Island, America Samoa need to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fba1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = get_html(f\"{BASE_URL}/agencies/whd/minimum-wage/state\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "cat = soup.find('div', {\"id\": \"states\"})\n",
    "state = cat.find_all('div')\n",
    "\n",
    "docs = {}\n",
    "\n",
    "for state_name in state:\n",
    "    if state_name.get('id').lower() == 'as': # America Samoa is a special case\n",
    "        continue\n",
    "    link = search_for_link(state_name)\n",
    "\n",
    "    # pega os irm√£os ap√≥s o <h2> (j√° como soup)\n",
    "    siblings = state_name.h2.find_next_siblings()\n",
    "    temp_soup = BeautifulSoup(\"\".join(str(s) for s in siblings), \"html.parser\")\n",
    "\n",
    "    # 1. Substitui footnotes\n",
    "    clean_text = adjust_text(temp_soup, link)\n",
    "\n",
    "    # 2. Normaliza texto\n",
    "    norm_text = normalize_text(clean_text)\n",
    "    norm_text = f\"For the state of the {state_name.h2.text} the laws of mimum wage is: \" + norm_text\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    docs[doc_id] = {\"text\": norm_text, \"metadata\": {\"state\": state_name.h2.text, 'text':norm_text}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff510355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50f9dcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"PINECONE_API\")\n",
    "pc = Pinecone(api_key=api_key)\n",
    "index_name = 'firtsindex'\n",
    "indexes = pc.list_indexes()\n",
    "index_names = [index.name for index in indexes]\n",
    "if index_name not in index_names:\n",
    "    pc.create_index(name=index_name,\n",
    "                dimension=384,\n",
    "                spec=ServerlessSpec(cloud='aws',region='us-east-1'),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc72060",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index('firstindex')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dd01d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_pinecone(doc, model, index):\n",
    "    for id, state in doc.items():\n",
    "        embeddings = model.encode(state['text']).tolist()\n",
    "\n",
    "        pinecone_data = {\n",
    "            \"id\": id,\n",
    "            \"values\": embeddings,\n",
    "            \"metadata\": state[\"metadata\"]\n",
    "        }\n",
    "\n",
    "        index.upsert(vectors=[pinecone_data])\n",
    "add_to_pinecone(docs,model, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb84d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(index, query, n_results):\n",
    "    query_embedding = model.encode([query]).tolist()[0]\n",
    "    results = index.query(vector=query_embedding,\n",
    "                          top_k=n_results,\n",
    "                          include_metadata=True)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f5f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "groq_api_key = os.getenv(\"GROQ_API\")\n",
    "client_groq = Groq(api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f20437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_context(results):\n",
    "    return \"\\n\\n\".join([match['metadata']['text'] for match in results['matches']])\n",
    "\n",
    "def get_prompt(context: str, query: str):\n",
    "    prompt = f\"\"\"Based on the following context and conversation history, \n",
    "        please provide a relevant and contextual response. \n",
    "        If the answer cannot be derived from the context, only use the conversation history \n",
    "        or say \"I cannot answer this based on the provided information.\"\n",
    "\n",
    "        Context from documents:\n",
    "        {context}\n",
    "\n",
    "        Human: {query}\n",
    "\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_response(query: str, context: str):\n",
    "    \"\"\"Generate a response using Groq's Llama-3.1-8b-instant with conversation history\"\"\"\n",
    "    # Construct the prompt\n",
    "    prompt = get_prompt(context, query)\n",
    "\n",
    "    try:\n",
    "        # Create the chat completion request\n",
    "        completion = client_groq.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions about the minimal wage on USA\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # Process and return the streamed response\n",
    "        response_content = []\n",
    "        for chunk in completion:\n",
    "            content = chunk.choices[0].delta.content or \"\"\n",
    "            response_content.append(content)\n",
    "\n",
    "        # Combine the response into a single string\n",
    "        response = \"\".join(response_content)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f1a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(pinecone_index, query: str, n_chunks: int = 2):\n",
    "    \"\"\"Perform RAG query: retrieve relevant chunks and generate an answer using Pinecone.\"\"\"\n",
    "    # Retrieve relevant chunks using Pinecone\n",
    "    results = semantic_search(pinecone_index, query, n_chunks)\n",
    "    context = get_context(results)\n",
    "\n",
    "    # Generate response using Groq\n",
    "    response = generate_response(query, context)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6c5c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta:  What is the California minimal wage? Have any extra points? Bullet points\n",
      "Reposta:  The basic minimum wage in California is $16.50 per hour. Additionally, there are the following premium pay rules for overtime hours worked:\n",
      "\n",
      "* Daily:\n",
      "  ‚Ä¢ Any work in excess of 8 hours in a workday is paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  ‚Ä¢ Any work in excess of 12 hours in a day is paid at double the regular rate of pay\n",
      "* Weekly:\n",
      "  ‚Ä¢ Any work in excess of 40 hours in a week is paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  ‚Ä¢ The first 8 hours worked on the seventh day of a workweek are paid at 1.5 times the regular rate of pay (time and a half)\n",
      "  ‚Ä¢ Any work in excess of 8 hours on the seventh day of a workweek is paid at double the regular rate of pay\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the California minimal wage? Have any extra points? Bullet points'\n",
    "response = rag_query(index, query)\n",
    "\n",
    "print('Pergunta: ', query)\n",
    "\n",
    "print('Reposta: ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feda743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded: True\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LightRAG' from 'lightrag' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY loaded:\u001b[39m\u001b[33m\"\u001b[39m, os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# --- LightRAG setup ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightrag\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightRAG\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gpt_4o_mini_complete, openai_embed\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightrag\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mshared_storage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_pipeline_status\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LightRAG' from 'lightrag' (unknown location)"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Quick check to confirm\n",
    "print(\"OPENAI_API_KEY loaded:\", os.getenv(\"OPENAI_API_KEY\") is not None)\n",
    "\n",
    "# --- LightRAG setup ---\n",
    "from lightrag import LightRAG\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=\"data/\",\n",
    "    embedding_func=openai_embed,\n",
    "    llm_model_func=gpt_4o_mini_complete,\n",
    ")\n",
    "\n",
    "# Initialize storages\n",
    "await rag.initialize_storages()\n",
    "await initialize_pipeline_status()\n",
    "\n",
    "# # Insert your docs\n",
    "for id, state in docs.items():\n",
    "    await rag.ainsert(state['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3bf5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"### Overview of Minimum Wage Rates\\n\\nThe highest minimum wage in the United States is currently set in the **District of Columbia**, where it stands at **$17.95** per hour. This rate reflects the jurisdiction's commitment to ensuring fair compensation for workers.\\n\\n### State Comparisons\\n\\nFollowing the District of Columbia, **California** has one of the highest state minimum wages at **$16.50** per hour, joined closely by **Washington** at **$16.66** per hour. **Connecticut** also maintains a significant minimum wage at **$16.35** per hour, while **Oregon** sets its standard rate at **$15.05**, with higher rates for specific areas like the Portland Metro Area at **$16.30** per hour.\\n\\n### Additional Context\\n\\nDifferent states have varying rates influenced by local economic conditions and labor policies. As such, the minimum wage shows significant diversity across the country, emphasizing the ongoing efforts to adjust for economic changes and living costs.\\n\\n### References\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source\\n- [KG] Unknown source \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightrag import QueryParam\n",
    "result = await rag.aquery(\"What is the biggest minimal wage?\", param=QueryParam(mode=\"mix\"))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4170de8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m         table = get_table(url = \u001b[33m'\u001b[39m\u001b[33mhttps://www.dol.gov/agencies/whd/state/child-labor/door-to-door-sales/2023\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     39\u001b[39m         display(table)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mextract_child_non_farm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mextract_child_non_farm\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_child_non_farm\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         table = \u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://www.dol.gov/agencies/whd/state/child-labor/door-to-door-sales/2023\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     39\u001b[39m         display(table)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_table\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_table\u001b[39m(url : \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         tables = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tables\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projeto_adp/.pj_mwgt/lib/python3.11/site-packages/pandas/io/html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projeto_adp/.pj_mwgt/lib/python3.11/site-packages/pandas/io/html.py:1003\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[32m   1005\u001b[39m ret = []\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projeto_adp/.pj_mwgt/lib/python3.11/site-packages/pandas/io/html.py:983\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m p = parser(\n\u001b[32m    973\u001b[39m     io,\n\u001b[32m    974\u001b[39m     compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m     storage_options,\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     tables = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[32m    986\u001b[39m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[33m\"\u001b[39m\u001b[33mseekable\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io.seekable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projeto_adp/.pj_mwgt/lib/python3.11/site-packages/pandas/io/html.py:249\u001b[39m, in \u001b[36m_HtmlFrameParser.parse_tables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     tables = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projeto_adp/.pj_mwgt/lib/python3.11/site-packages/pandas/io/html.py:598\u001b[39m, in \u001b[36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[39m\u001b[34m(self, document, match, attrs)\u001b[39m\n\u001b[32m    596\u001b[39m tables = document.find_all(element_name, attrs=attrs)\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo tables found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    600\u001b[39m result = []\n\u001b[32m    601\u001b[39m unique_tables = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: No tables found"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def get_table(url : str):\n",
    "        tables = pd.read_html(url)\n",
    "        return tables\n",
    "    \n",
    "def get_footnotes( url: str, div: str = \"content\"):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    content = soup.find(\"div\", id=div)\n",
    "    if not content:\n",
    "        return []\n",
    "\n",
    "    table = content.find(\"table\")\n",
    "\n",
    "    if table:\n",
    "        footnote_elements = []\n",
    "        for sibling in table.find_next_siblings():\n",
    "            # Para evitar ru√≠do (espa√ßos em branco, '\\n', etc.)\n",
    "            if getattr(sibling, \"name\", None):\n",
    "                footnote_elements.append(sibling)\n",
    "        return footnote_elements\n",
    "\n",
    "    elements = list(content.children)\n",
    "    start_index = None\n",
    "    for i, el in enumerate(elements):\n",
    "        if hasattr(el, \"get_text\") and \"FOOTNOTE\" in el.get_text().upper():\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index is not None:\n",
    "        return elements[start_index + 1 :]\n",
    "    else:\n",
    "        return []\n",
    "def extract_child_non_farm():\n",
    "        table = get_table(url = 'https://www.dol.gov/agencies/whd/state/child-labor/door-to-door-sales/2023')[0]\n",
    "        \n",
    "        display(table)\n",
    "extract_child_non_farm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "828ef7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import asyncpg\n",
    "\n",
    "from lightrag import LightRAG\n",
    "\n",
    "# Importe suas fun√ß√µes de LLM e Embedding\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
    "\n",
    "async def setup_lightrag_with_postgres():\n",
    "    \"\"\"\n",
    "    Inicializa o LightRAG com PostgreSQL, garantindo que o AGE e o contexto\n",
    "    do search_path estejam ativos antes de inicializar os storages.\n",
    "    \"\"\"\n",
    "\n",
    "    db_uri = os.environ.get(\"POSTGRES_DB_URI\")\n",
    "    if not db_uri:\n",
    "        raise ValueError(\"A vari√°vel de ambiente POSTGRES_DB_URI n√£o foi definida.\")\n",
    "\n",
    "    print(f\"Vari√°vel POSTGRES_DB_URI encontrada.\")\n",
    "\n",
    "    # üîπ 1. Carrega o AGE e configura o search_path dentro da conex√£o\n",
    "    print(\"Carregando AGE e configurando o contexto no Postgres...\")\n",
    "    conn = await asyncpg.connect(db_uri.replace(\"+asyncpg\", \"\"))  # remove o prefixo asyncpg\n",
    "    await conn.execute(\"LOAD 'age';\")\n",
    "    await conn.execute(\"SET search_path = ag_catalog, \\\"$user\\\", public;\")\n",
    "    await conn.close()\n",
    "    print(\"‚úÖ AGE carregado e contexto configurado.\\n\")\n",
    "\n",
    "    # üîπ 2. Inicializa o LightRAG\n",
    "    print(\"Inicializando o objeto LightRAG...\")\n",
    "    rag = LightRAG(\n",
    "        kv_storage=\"PGKVStorage\",\n",
    "        vector_storage=\"PGVectorStorage\",\n",
    "        graph_storage=\"PGGraphStorage\",\n",
    "        doc_status_storage=\"PGDocStatusStorage\",\n",
    "        llm_model_func=gpt_4o_mini_complete,\n",
    "        embedding_func=openai_embed\n",
    "    )\n",
    "\n",
    "    # üîπ 3. Inicializa as tabelas\n",
    "    print(\"Inicializando tabelas e schemas no Postgres...\")\n",
    "    await rag.initialize_storages()\n",
    "\n",
    "    print(\"‚úÖ LightRAG est√° pronto para usar o Postgres como backend completo!\\n\")\n",
    "    return rag\n",
    "\n",
    "async def main():\n",
    "    os.environ[\"POSTGRES_DB_URI\"] = \"postgresql+asyncpg://agermano:devpass@localhost:5432/lightrag_db\"\n",
    "    os.environ[\"POSTGRES_USER\"] = \"agermano\"\n",
    "    os.environ[\"POSTGRES_PASSWORD\"] = \"devpass\"\n",
    "    os.environ[\"POSTGRES_DATABASE\"] = \"lightrag_db\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "    \n",
    "    if not os.environ.get(\"DB_URI\") or not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        print(\"ERRO: Por favor, defina as vari√°veis de ambiente DB_URI e OPENAI_API_KEY.\")\n",
    "        return\n",
    "\n",
    "    rag_instance = await setup_lightrag_with_postgres()\n",
    "    \n",
    "    # Teste de inser√ß√£o\n",
    "    print(\"\\nTestando inser√ß√£o de dados...\")\n",
    "    await rag_instance.insert(\"O LightRAG agora salva tudo no Postgres. (Forma simplificada)\")\n",
    "    print(\"Inser√ß√£o conclu√≠da.\")\n",
    "    \n",
    "    # Teste de consulta\n",
    "    print(\"Testando consulta RAG...\")\n",
    "    response = await rag_instance.call(\"Onde o LightRAG salva os dados?\")\n",
    "    print(\"\\n--- Resposta do RAG ---\")\n",
    "    print(response)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f1324b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [default] PostgreSQL Graph initialized: graph_name='chunk_entity_relation'\n",
      "INFO: PostgreSQL, AGE extension enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vari√°vel POSTGRES_DB_URI encontrada.\n",
      "Carregando AGE e configurando o contexto no Postgres...\n",
      "‚úÖ AGE carregado e contexto configurado.\n",
      "\n",
      "Inicializando o objeto LightRAG...\n",
      "Inicializando tabelas e schemas no Postgres...\n",
      "‚úÖ LightRAG est√° pronto para usar o Postgres como backend completo!\n",
      "\n",
      "\n",
      "Testando inser√ß√£o de dados...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apenas chame a fun√ß√£o main com 'await' na frente\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Teste de inser√ß√£o\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTestando inser√ß√£o de dados...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mrag_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mO LightRAG agora salva tudo no Postgres. (Forma simplificada)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInser√ß√£o conclu√≠da.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Teste de consulta\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_adp/.proj_cdia/lib/python3.12/site-packages/lightrag/lightrag.py:1092\u001b[39m, in \u001b[36mLightRAG.insert\u001b[39m\u001b[34m(self, input, split_by_character, split_by_character_only, ids, file_paths, track_id)\u001b[39m\n\u001b[32m   1076\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sync Insert documents with checkpoint support\u001b[39;00m\n\u001b[32m   1077\u001b[39m \n\u001b[32m   1078\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1089\u001b[39m \u001b[33;03m    str: tracking ID for monitoring processing status\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1091\u001b[39m loop = always_get_an_event_loop()\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mainsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_by_character\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_by_character_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrack_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/base_events.py:663\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    652\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[32m    653\u001b[39m \n\u001b[32m    654\u001b[39m \u001b[33;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    660\u001b[39m \u001b[33;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[32m    661\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m new_task = \u001b[38;5;129;01mnot\u001b[39;00m futures.isfuture(future)\n\u001b[32m    666\u001b[39m future = tasks.ensure_future(future, loop=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/base_events.py:622\u001b[39m, in \u001b[36mBaseEventLoop._check_running\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_running():\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mThis event loop is already running\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    625\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mCannot run the event loop while another loop is running\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "# Apenas chame a fun√ß√£o main com 'await' na frente\n",
    "    \n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".proj_cdia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
